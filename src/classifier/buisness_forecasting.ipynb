{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b48057a",
   "metadata": {},
   "source": [
    "This file forecasts derailment/subreddit using BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2490209",
   "metadata": {},
   "source": [
    "# 1. Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a208fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "test_size = 0.2\n",
    "labels = [True, False]  # replace with your real labels\n",
    "num_labels = len(labels)\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d99869",
   "metadata": {},
   "source": [
    "# 2. Read and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c85c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from convokit import Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab11998",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"the corpus of emails here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "email = []\n",
    "is_buisness = []\n",
    "\n",
    "for convo in corpus.iter_emails():\n",
    "    email.append('the email content here')\n",
    "    is_buisness.append(\"if the email is in enron or not here\")\n",
    "\n",
    "\n",
    "# Zip the lists together\n",
    "combined = list(zip(email, is_buisness))\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Unzip back into two lists\n",
    "email_shuffled, is_buisness_shuffled = zip(*combined)\n",
    "\n",
    "# Convert back to lists (optional)\n",
    "email_shuffled = list(email_shuffled)\n",
    "is_buisness_shuffled = list(is_buisness_shuffled)\n",
    "\n",
    "pre_dataframe = {\"email\": email_shuffled, \"is_buisness\":is_buisness_shuffled}\n",
    "df = pd.DataFrame(pre_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd795488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCD</th>\n",
       "      <th>derails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Both participants engage in a discussion with ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The conversation begins with Speaker1 presenti...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The discussion begins with Speaker1 presenting...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The conversation begins with four speakers exp...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The conversation began with Speaker1 presentin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SCD  derails\n",
       "0  Both participants engage in a discussion with ...    False\n",
       "1  The conversation begins with Speaker1 presenti...    False\n",
       "2  The discussion begins with Speaker1 presenting...     True\n",
       "3  The conversation begins with four speakers exp...     True\n",
       "4  The conversation began with Speaker1 presentin...     True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900f633",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68961334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "422ca103",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df[\"derails\"].tolist())\n",
    "df['label'] = le.transform(df[\"derails\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6963707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>convo_id</th>\n",
       "      <th>SCD</th>\n",
       "      <th>derails</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dgd3dw3</td>\n",
       "      <td>Both participants engage in a discussion with ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dp22jzs</td>\n",
       "      <td>The conversation begins with Speaker1 presenti...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dyl0uu1</td>\n",
       "      <td>The discussion begins with Speaker1 presenting...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d8fk4at</td>\n",
       "      <td>The conversation begins with four speakers exp...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drh8oaq</td>\n",
       "      <td>The conversation began with Speaker1 presentin...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  convo_id                                                SCD  derails  label\n",
       "0  dgd3dw3  Both participants engage in a discussion with ...    False      0\n",
       "1  dp22jzs  The conversation begins with Speaker1 presenti...    False      0\n",
       "2  dyl0uu1  The discussion begins with Speaker1 presenting...     True      1\n",
       "3  d8fk4at  The conversation begins with four speakers exp...     True      1\n",
       "4  drh8oaq  The conversation began with Speaker1 presentin...     True      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bfae77",
   "metadata": {},
   "source": [
    "### Train/Test/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d293472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b12462f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split off 20% for test\n",
    "df_train_val, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now split the remaining 80% into 60% train and 20% val\n",
    "# 20% out of the remaining 80% is 0.25 of that chunk\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Hugging Face format\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train.reset_index(drop=True)),\n",
    "    \"validation\": Dataset.from_pandas(df_val.reset_index(drop=True)),\n",
    "    \"test\": Dataset.from_pandas(df_test.reset_index(drop=True)),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153d3c2",
   "metadata": {},
   "source": [
    "### Convert to correct dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d048484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ee517",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a9a1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc835bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"email\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b74e5d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f3e5d52ec449fe874ed45a0ce5ed98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7944766e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e323721211db4f579b3f1dfd971ad214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10f444",
   "metadata": {},
   "source": [
    "# 3. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2432b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dca7479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8a5f9",
   "metadata": {},
   "source": [
    "# 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f78f911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6371c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "904c8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    return {\"eval_accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45a4e244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2109262/2686343222.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from ray import tune\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",                 # âœ… clean & modern\n",
    "    save_strategy=\"epoch\",                 # âœ… matches eval\n",
    "    save_total_limit=2,                    # âœ… keeps best 2 checkpoints\n",
    "    load_best_model_at_end=True,           # âœ… will restore best version\n",
    "    metric_for_best_model=\"eval_accuracy\", # âœ… or use \"eval_accuracy\"\n",
    "    greater_is_better=True,                # âœ… for accuracy\n",
    "    report_to=\"none\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=128,       # for speed\n",
    "    per_device_eval_batch_size=256,        # speed\n",
    "    fp16=True,                             # speed\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.05,\n",
    ")\n",
    "\n",
    "def ray_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": tune.loguniform(1e-5, 5e-5),\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    # model=model,\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]  # ðŸ‘ˆ Add this line\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a28294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_objective(metrics):\n",
    "    return metrics[\"eval_accuracy\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5b24e",
   "metadata": {},
   "source": [
    "Now re-generate the model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9da850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 01:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.680469</td>\n",
       "      <td>0.589481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.651935</td>\n",
       "      <td>0.640614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.646100</td>\n",
       "      <td>0.631125</td>\n",
       "      <td>0.656684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.628200</td>\n",
       "      <td>0.635144</td>\n",
       "      <td>0.662527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.611700</td>\n",
       "      <td>0.623476</td>\n",
       "      <td>0.660336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.629160</td>\n",
       "      <td>0.677137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.591500</td>\n",
       "      <td>0.628590</td>\n",
       "      <td>0.677137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.581900</td>\n",
       "      <td>0.630778</td>\n",
       "      <td>0.669832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.558200</td>\n",
       "      <td>0.626109</td>\n",
       "      <td>0.672023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.664994</td>\n",
       "      <td>0.650840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=330, training_loss=0.612227098869555, metrics={'train_runtime': 96.9912, 'train_samples_per_second': 423.131, 'train_steps_per_second': 3.402, 'total_flos': 5240210222975040.0, 'train_loss': 0.612227098869555, 'epoch': 10.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Retrain and save\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model('BERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a51dbed",
   "metadata": {},
   "source": [
    "# 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a94c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      2047\n",
      "           1       0.71      0.72      0.71      2057\n",
      "\n",
      "    accuracy                           0.71      4104\n",
      "   macro avg       0.71      0.71      0.71      4104\n",
      "weighted avg       0.71      0.71      0.71      4104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_train)\n",
    "preds = np.argmax(preds[:3][0],axis=1)\n",
    "GT = df_train['label'].tolist()\n",
    "print(classification_report(GT,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bed9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.49      0.50       712\n",
      "           1       0.47      0.49      0.48       657\n",
      "\n",
      "    accuracy                           0.49      1369\n",
      "   macro avg       0.49      0.49      0.49      1369\n",
      "weighted avg       0.49      0.49      0.49      1369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = trainer.predict(tokenized_test)\n",
    "logits = output.predictions  # raw model output before argmax\n",
    "preds = np.argmax(logits, axis=1)  # class with highest score\n",
    "\n",
    "GT = df_val['label'].tolist()  \n",
    "print(classification_report(GT, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5b5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.677136596055515,\n",
       " 'eval_loss': 0.6291604042053223,\n",
       " 'eval_runtime': 0.912,\n",
       " 'eval_samples_per_second': 1501.049,\n",
       " 'eval_steps_per_second': 6.579,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
