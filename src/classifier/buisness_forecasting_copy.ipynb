{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b48057a",
   "metadata": {},
   "source": [
    "This file forecasts derailment/subreddit using BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2490209",
   "metadata": {},
   "source": [
    "# 1. Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2a208fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "test_size = 0.2\n",
    "labels = [True, False]  # replace with your real labels\n",
    "num_labels = len(labels)\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d99869",
   "metadata": {},
   "source": [
    "# 2. Read and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95c85c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ab11998",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = os.path.join('..', '..', 'Data', 'processed', 'email_label_dict_balanced.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65b09fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 31,908 emails\n",
      "Casual: 5,318 | Business: 26,590\n",
      "Ratio: 1:5.0\n"
     ]
    }
   ],
   "source": [
    "# Load the balanced dictionary\n",
    "with open(corpus, 'rb') as f:\n",
    "    emails_and_tag = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(emails_and_tag):,} emails\")\n",
    "\n",
    "# Check class distribution\n",
    "casual_count = sum(1 for v in emails_and_tag.values() if v == 0)\n",
    "business_count = sum(1 for v in emails_and_tag.values() if v == 1)\n",
    "print(f\"Casual: {casual_count:,} | Business: {business_count:,}\")\n",
    "print(f\"Ratio: 1:{business_count/casual_count:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ae4baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "emails = []\n",
    "is_business = []\n",
    "\n",
    "for key, value in emails_and_tag.items():\n",
    "    emails.append(key)\n",
    "    is_business.append(value) \n",
    "\n",
    "\n",
    "# Zip the lists together\n",
    "combined = list(zip(emails, is_business))\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Unzip back into two lists\n",
    "email_shuffled, is_buisness_shuffled = zip(*combined)\n",
    "\n",
    "# Convert back to lists (optional)\n",
    "email_shuffled = list(email_shuffled)\n",
    "is_buisness_shuffled = list(is_buisness_shuffled)\n",
    "\n",
    "pre_dataframe = {\"email\": email_shuffled, \"is_buisness\":is_buisness_shuffled}\n",
    "df = pd.DataFrame(pre_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd795488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>is_buisness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: hey\\n\\nSusan,\\nHey, just thought I'd ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: eThink About It: October 23, 2000\\n\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: RE: Status\\n\\nKeith:\\nTomorrow works ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: Re: USA USA WE ARE NUMBER ....six.\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: [use Perl] Headlines for 2002-10-03\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  is_buisness\n",
       "0  Subject: hey\\n\\nSusan,\\nHey, just thought I'd ...            1\n",
       "1  Subject: eThink About It: October 23, 2000\\n\\n...            1\n",
       "2  Subject: RE: Status\\n\\nKeith:\\nTomorrow works ...            1\n",
       "3  Subject: Re: USA USA WE ARE NUMBER ....six.\\n\\...            0\n",
       "4  Subject: [use Perl] Headlines for 2002-10-03\\n...            0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900f633",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68961334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "422ca103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(df[\"derails\"].tolist())\n",
    "# df['label'] = le.transform(df[\"derails\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6963707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>is_buisness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: hey\\n\\nSusan,\\nHey, just thought I'd ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: eThink About It: October 23, 2000\\n\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: RE: Status\\n\\nKeith:\\nTomorrow works ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: Re: USA USA WE ARE NUMBER ....six.\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: [use Perl] Headlines for 2002-10-03\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  is_buisness\n",
       "0  Subject: hey\\n\\nSusan,\\nHey, just thought I'd ...            1\n",
       "1  Subject: eThink About It: October 23, 2000\\n\\n...            1\n",
       "2  Subject: RE: Status\\n\\nKeith:\\nTomorrow works ...            1\n",
       "3  Subject: Re: USA USA WE ARE NUMBER ....six.\\n\\...            0\n",
       "4  Subject: [use Perl] Headlines for 2002-10-03\\n...            0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bfae77",
   "metadata": {},
   "source": [
    "### Train/Test/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d293472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b12462f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split off 20% for test\n",
    "df_train_val, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now split the remaining 80% into 60% train and 20% val\n",
    "# 20% out of the remaining 80% is 0.25 of that chunk\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Hugging Face format\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train.reset_index(drop=True)),\n",
    "    \"validation\": Dataset.from_pandas(df_val.reset_index(drop=True)),\n",
    "    \"test\": Dataset.from_pandas(df_test.reset_index(drop=True)),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153d3c2",
   "metadata": {},
   "source": [
    "### Convert to correct dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d048484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ee517",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a9a1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bc835bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethansandoval/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"email\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b74e5d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d15262a27d46cebf29fc8916a1a1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7944766e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a0ff00aa7a425bb2e17af4d902ebd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10f444",
   "metadata": {},
   "source": [
    "# 3. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2432b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dca7479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8a5f9",
   "metadata": {},
   "source": [
    "# 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f78f911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6371c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "904c8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    return {\"eval_accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45a4e244",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or NPU devices.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer, EarlyStoppingCallback\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tune\n\u001b[0;32m----> 4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      5\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m     logging_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,                 \u001b[38;5;66;03m# âœ… clean & modern\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,                 \u001b[38;5;66;03m# âœ… matches eval\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,                    \u001b[38;5;66;03m# âœ… keeps best 2 checkpoints\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,           \u001b[38;5;66;03m# âœ… will restore best version\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     metric_for_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# âœ… or use \"eval_accuracy\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,                \u001b[38;5;66;03m# âœ… for accuracy\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-5\u001b[39m,\n\u001b[1;32m     16\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,       \u001b[38;5;66;03m# for speed\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,        \u001b[38;5;66;03m# speed\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,                             \u001b[38;5;66;03m# speed\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     20\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mray_hp_space\u001b[39m(trial):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39mloguniform(\u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m5e-5\u001b[39m),\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m: tune\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m     27\u001b[0m     }\n",
      "File \u001b[0;32m<string>:114\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1405\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[1;32m   1404\u001b[0m ):\n\u001b[0;32m-> 1405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or NPU devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1408\u001b[0m     )\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[1;32m   1418\u001b[0m ):\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1420\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBF16 Mixed precision training with AMP (`--bf16`) and BF16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--bf16_full_eval`) can only be used on CUDA or CPU/TPU/NeuronCore devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1422\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or NPU devices."
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from ray import tune\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",                 # âœ… clean & modern\n",
    "    save_strategy=\"epoch\",                 # âœ… matches eval\n",
    "    save_total_limit=2,                    # âœ… keeps best 2 checkpoints\n",
    "    load_best_model_at_end=True,           # âœ… will restore best version\n",
    "    metric_for_best_model=\"eval_accuracy\", # âœ… or use \"eval_accuracy\"\n",
    "    greater_is_better=True,                # âœ… for accuracy\n",
    "    report_to=\"none\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=128,       # for speed\n",
    "    per_device_eval_batch_size=256,        # speed\n",
    "    fp16=True,                             # speed\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.05,\n",
    ")\n",
    "\n",
    "def ray_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": tune.loguniform(1e-5, 5e-5),\n",
    "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    # model=model,\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]  # ðŸ‘ˆ Add this line\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_objective(metrics):\n",
    "    return metrics[\"eval_accuracy\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5b24e",
   "metadata": {},
   "source": [
    "Now re-generate the model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9da850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 01:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.680469</td>\n",
       "      <td>0.589481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.651935</td>\n",
       "      <td>0.640614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.646100</td>\n",
       "      <td>0.631125</td>\n",
       "      <td>0.656684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.628200</td>\n",
       "      <td>0.635144</td>\n",
       "      <td>0.662527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.611700</td>\n",
       "      <td>0.623476</td>\n",
       "      <td>0.660336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.629160</td>\n",
       "      <td>0.677137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.591500</td>\n",
       "      <td>0.628590</td>\n",
       "      <td>0.677137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.581900</td>\n",
       "      <td>0.630778</td>\n",
       "      <td>0.669832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.558200</td>\n",
       "      <td>0.626109</td>\n",
       "      <td>0.672023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.664994</td>\n",
       "      <td>0.650840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=330, training_loss=0.612227098869555, metrics={'train_runtime': 96.9912, 'train_samples_per_second': 423.131, 'train_steps_per_second': 3.402, 'total_flos': 5240210222975040.0, 'train_loss': 0.612227098869555, 'epoch': 10.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Retrain and save\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model('BERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a51dbed",
   "metadata": {},
   "source": [
    "# 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a94c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      2047\n",
      "           1       0.71      0.72      0.71      2057\n",
      "\n",
      "    accuracy                           0.71      4104\n",
      "   macro avg       0.71      0.71      0.71      4104\n",
      "weighted avg       0.71      0.71      0.71      4104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_train)\n",
    "preds = np.argmax(preds[:3][0],axis=1)\n",
    "GT = df_train['label'].tolist()\n",
    "print(classification_report(GT,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bed9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.49      0.50       712\n",
      "           1       0.47      0.49      0.48       657\n",
      "\n",
      "    accuracy                           0.49      1369\n",
      "   macro avg       0.49      0.49      0.49      1369\n",
      "weighted avg       0.49      0.49      0.49      1369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = trainer.predict(tokenized_test)\n",
    "logits = output.predictions  # raw model output before argmax\n",
    "preds = np.argmax(logits, axis=1)  # class with highest score\n",
    "\n",
    "GT = df_val['label'].tolist()  \n",
    "print(classification_report(GT, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5b5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.677136596055515,\n",
       " 'eval_loss': 0.6291604042053223,\n",
       " 'eval_runtime': 0.912,\n",
       " 'eval_samples_per_second': 1501.049,\n",
       " 'eval_steps_per_second': 6.579,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
